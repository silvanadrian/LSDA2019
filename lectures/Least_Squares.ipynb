{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(n=250):\n",
    "    \"\"\" Creates a simple 1D dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    numpy.random.seed(0)\n",
    "    \n",
    "    X = numpy.linspace(0, 3*numpy.pi, n)\n",
    "    y = 0.5*numpy.sin(X) + numpy.random.normal(0, 0.1, n)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquaresRegression():\n",
    "    \n",
    "    def __init__(self, lam=1.0, kernel=\"rbf\", gamma=1.0, r=None, random_state=0):\n",
    "        \"\"\" Instantiates the regression model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lam : float, default 1.0\n",
    "            The regularization parameter lambda\n",
    "        kernel : string, default 'rbf'\n",
    "            The kernel to be used\n",
    "        gamma : float, default 1.0\n",
    "            The kernel width gamma for the RBF kernel\n",
    "        r : int or None, default None\n",
    "            If None, then use all the training instances\n",
    "            to represent the model. Otherwise, only \n",
    "            r random training instances are used (1 <= r <= n).\n",
    "        random_state : int, default 0\n",
    "            The random state (seed) to be used.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.r = r\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Returns the parameters of the model\n",
    "        \"\"\"\n",
    "        \n",
    "        return {\"lam\": self.lam, \n",
    "                \"kernel\": self.kernel, \n",
    "                \"gamma\": self.gamma, \n",
    "                \"r\": self.r,\n",
    "                \"random_state\": self.random_state}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        \"\"\" Sets the parameters of the model\n",
    "        \"\"\"        \n",
    "        \n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the regression model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        y : Array of shape [n_samples, 1]\n",
    "        \"\"\"   \n",
    "        \n",
    "        numpy.random.seed(self.random_state)\n",
    "        \n",
    "        # make sure that we have numpy arrays; also\n",
    "        # reshape the array X to ensure that we have\n",
    "        # a multidimensional numpy array (ndarray);\n",
    "        # for y, we want to have a column vector\n",
    "        X = numpy.array(X).reshape((X.shape[0], -1))\n",
    "        y = numpy.array(y).reshape((len(y), 1))\n",
    "\n",
    "        self._Xtrain = X\n",
    "        self._ytrain = y\n",
    "        \n",
    "        if self.r is None:\n",
    "        \n",
    "            km = self._compute_kernel_matrix(self._Xtrain, self._Xtrain)\n",
    "            \n",
    "            shifted_km = km + len(self._ytrain) * self.lam * numpy.identity(len(self._Xtrain))\n",
    "            \n",
    "            # NOT RECOMMENDED\n",
    "            #self._c = numpy.dot(numpy.linalg.inv(shifted_km), self._ytrain)     \n",
    "            self._c = numpy.linalg.solve(shifted_km, self._ytrain)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            assert self.r >= 1\n",
    "            assert self.r <= X.shape[0]\n",
    "            \n",
    "            rsub = sorted(numpy.random.choice(X.shape[0], self.r, replace=False))\n",
    "            \n",
    "            self._Xtrain_sub = self._Xtrain[rsub]    \n",
    "            \n",
    "            kr = self._compute_kernel_matrix(self._Xtrain_sub, self._Xtrain)\n",
    "            krr = self._compute_kernel_matrix(self._Xtrain_sub, self._Xtrain_sub)\n",
    "            \n",
    "            km = numpy.dot(kr, kr.T)\n",
    "            km = km + len(self._ytrain) * self.lam * krr\n",
    "            \n",
    "            right = numpy.dot(kr, self._ytrain)\n",
    "            \n",
    "            # NOT RECOMMENDED!\n",
    "            #self._c = numpy.dot(numpy.linalg.inv(km), right)\n",
    "            \n",
    "            self._c = numpy.linalg.solve(km, right)\n",
    "\n",
    "        return self\n",
    "     \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Computes predictions for a new set of points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : Array of shape [n_samples, 1]\n",
    "        \"\"\"           \n",
    "        \n",
    "        # make sure that we have numpy arrays; also\n",
    "        # reshape the array X to ensure that we have\n",
    "        # a multidimensional numpy array (ndarray)\n",
    "        X = numpy.array(X).reshape((X.shape[0], -1))\n",
    "\n",
    "        if self.r is None:\n",
    "            \n",
    "            km = self._compute_kernel_matrix(X, self._Xtrain)\n",
    "            preds = numpy.dot(km, self._c)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            km = self._compute_kernel_matrix(X, self._Xtrain_sub)\n",
    "            preds = numpy.dot(km, self._c)\n",
    "    \n",
    "        return preds\n",
    "            \n",
    "    def _compute_kernel_matrix(self, X1, X2):\n",
    "        \"\"\" Computes the kernel matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.kernel == \"rbf\":\n",
    "            \n",
    "            km = numpy.empty((X1.shape[0], X2.shape[0]), dtype=numpy.float64)\n",
    "            \n",
    "            for i in range(X1.shape[0]):\n",
    "                for j in range(X2.shape[0]):\n",
    "                    diff = X1[i] - X2[j]\n",
    "                    tmp = numpy.dot(diff, diff)\n",
    "                    km[i,j] = numpy.exp(- self.gamma * tmp)\n",
    "                    \n",
    "\n",
    "            return km\n",
    "        \n",
    "        elif self.kernel == \"fast_rbf\":\n",
    "            \n",
    "            norms1 = []\n",
    "            for i in range(X1.shape[0]):\n",
    "                norms1.append(numpy.dot(X1[i], X1[i].T))\n",
    "            norms1 = numpy.array(norms1).reshape((len(norms1),-1))\n",
    "            norms1 = norms1 * numpy.ones((1, X2.shape[0]), dtype=numpy.float64)\n",
    "                        \n",
    "            norms2 = []\n",
    "            for j in range(X2.shape[0]):\n",
    "                norms2.append(numpy.dot(X2[j], X2[j].T))\n",
    "            norms2 = numpy.array(norms2).reshape((len(norms2), -1))\n",
    "            norms2 = numpy.ones((X1.shape[0], 1), dtype=numpy.float64) * norms2.T\n",
    "            km = norms1 + norms2 - 2*numpy.dot(X1, X2.T)\n",
    "            \n",
    "            km = -self.gamma * km\n",
    "            km = numpy.exp(km)\n",
    "            \n",
    "            return km\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            raise Exception(\"Unknown kernel: {}\".format(self.kernel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes: Let's generate some toy data to illustrate the effect of the different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = get_dataset(n=500)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "model = LeastSquaresRegression(kernel=\"fast_rbf\", lam=0.01, gamma=1, r=200)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# plot test points and predictions\n",
    "plt.scatter(X_test, y_test, s=100, c=\"b\", edgecolor=\"k\", linewidths=1, label=\"True\")\n",
    "plt.scatter(X_test, preds, s=100, c=\"r\", edgecolor=\"k\", linewidths=1, label=\"Predictions\")\n",
    "\n",
    "# plot model\n",
    "x = numpy.linspace(X.min(), X.max(), 500)\n",
    "plt.plot(x, model.predict(x), \"-k\", alpha=0.8, linewidth=3.0, label=\"Model\")\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(loc=0)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
