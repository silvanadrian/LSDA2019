{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow](https://www.tensorflow.org/) is an open-source software library for numerical computations developed by Google. Its main application area is machine learning, in particular deep learning with neural networks. TensorFlow  makes it very easy to distribute computations over CPUs and GPUs. Thus, it is very well suited for large-scale data analysis.\n",
    "\n",
    "A comparison of deep learning frameworks taken from [towardsdatascience.com](https://towardsdatascience.com/):\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*dYjDEI0mLpsCOySKUuX1VA.png\"></img>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*s_BwkYxpGv34vjOHi8tDzg.png\"></img>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*eOOYV3C5klsuVBMX31ngxw.png\"></img>\n",
    "\n",
    "The following introduction is based on the [Getting Started With TensorFlow](https://www.tensorflow.org/get_started/get_started) tutorial and the first lessons from [LearningTensorFlow](http://learningtensorflow.com/). Go to these sites to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing TensorFlow and checking its version, which we assume to be at least 2 in this tutortial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using *Google Colaborator* notebook environment, you may need to install the proper TensorFlow version first using something like  `!pip install -q tensorflow==2.0.0-alpha0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a TensorFlow program, the computational operations are organized in a graph. The nodes correspond to particular operations. The edges define the data flow between the nodes. These data are tensors, which in this context are simply multidimensional arrays. \n",
    "In TensorFlow versions larger than 2.0.0, this can almost be regarded as an implementation detail which is  hidden from the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node can take some tensors as input and outputs a tensor. One basic type of node without input is a constant node representing a constant tensor. Let's define some constants holding tensors of different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32, name='Klaus') # rank 0 tensor; scalar with shape [], tf.float32 is default and can be omitted\n",
    "print(\"node1, rank 0 tensor, a scalar:\", node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rank 1 tensor; a vector:\", tf.constant([1. ,2., 3.]))\n",
    "print(\"rank 2 tensor; a matrix:\", tf.constant([[1., 2., 3.], [4., 5., 6.]]))\n",
    "print(\"rank 3 tensor:\", tf.constant([[[1., 2., 3.], [1., 2., 3.]], [[7., 8., 9.], [1., 2., 3.]]] ) )\n",
    "print(\"rank 3 tensor:\", tf.constant([[[1., 2., 3.], [4., 5., 6.]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the shape and type of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node1.shape)\n",
    "print(node1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have the advantage of being easily handled by GPUs and  TPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some simple computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0)\n",
    "print(\"node1:\", node2)\n",
    "\n",
    "node2 = tf.constant(4.0)\n",
    "print(\"node2:\", node2)\n",
    "\n",
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3:\", node3)\n",
    "\n",
    "node4 = node3 + node2  # The plus operator is mapped to tf.add\n",
    "print(\"node4:\", node4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0)\n",
    "print(\"node1:\", node1)\n",
    "\n",
    "x = 5.0\n",
    "print(\"node2:\", x)\n",
    "\n",
    "node3 = tf.add(node1, x)  # x is automatically converted\n",
    "print(\"node3:\", node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow and NumPy\n",
    "\n",
    "TensorFlow and NumPy go hand-in-hand, as shown in this example from the official TensorFlow documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert NumPy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to NumPy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a NumPy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, we can distinguish between\n",
    "\n",
    "1. Defining the computational graph, and\n",
    "\n",
    "2. Running the computational graph.\n",
    "\n",
    "In TensorFlow 2 uses \"eager execution\" which hides this implementation detail. Running graphs now looks like executing normal Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to group operations in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_TF_function():\n",
    "    node1 = tf.constant(3.0)\n",
    "    node2 = tf.constant(4.0)\n",
    "    return tf.add(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_TF_function())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the decoration `tf.function` to the functions \n",
    "has the effect that all operations are combined in a single graph, which is \n",
    "compiled just-in-time. This speeds-up computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def first_TF_function():\n",
    "    node1 = tf.constant(3.0)\n",
    "    node2 = tf.constant(4.0)\n",
    "    return tf.add(node1, node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding the decoration, TensorFlow tries to covert the code in the function into TensorFlow operations, which can be executed on GPUs or TPUs. Without decoration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_TF_function():\n",
    "    node1 = 3.0\n",
    "    node2 = 4.0\n",
    "    return node1 + node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_TF_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With decoration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def first_TF_function():\n",
    "    node1 = 3.0\n",
    "    node2 = 4.0\n",
    "    return node1 + node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_TF_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "# Import for timestamp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def my_func():\n",
    "  node1 = tf.constant(3.0, name=\"a\")\n",
    "  node2 = tf.constant(4.0, name=\"b\")\n",
    "  return tf.add(node1, node2, name=\"sum\")\n",
    "\n",
    "# Set up logging.\n",
    "writer = tf.summary.create_file_writer(\"logs/func/trial0\")\n",
    "\n",
    "# Bracket the function call with\n",
    "# tf.summary.trace_on() and tf.summary.trace_export().\n",
    "tf.summary.trace_on(graph=True)\n",
    "# Call only one tf.function when tracing.\n",
    "z = my_func()\n",
    "#z = first_TF_function()\n",
    "with writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You  can call \n",
    "\n",
    "`tensorboard --logdir=/tmp/LSDAIntro/`\n",
    "\n",
    "outside the notebook, giving you a link to view the graph (and more) in a browser (via opening, e.g., `http://localhost:6006`).\n",
    "You may have to locate the `tensorboard` executable first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant([1, 2, 3])\n",
    "node2 = tf.constant([4, 5, 6])\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant([1, 2, 3])\n",
    "node2 = tf.constant([4])\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "node2 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "node2 = tf.constant(1)\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it gets more tricky, have a close look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "node2 = tf.constant([100, 101, 103])\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "node2 = tf.constant([100, 103])\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "node2 = tf.constant([[100],[103]])\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External inputs are fed into the graph via arguments to functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def second_TF_function(x):\n",
    "    node1 = 3.0\n",
    "    return node1 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_TF_function(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph can of course contain also variables, for example the parameters of a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.ones(shape=(2, 2)), tf.float32, name=\"W\")\n",
    "b = tf.Variable(tf.zeros(shape=(2)), name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the value of a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)\n",
    "b.assign([-1.,1])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an affine linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 2\n",
    "out_dim = 2\n",
    "\n",
    "W = tf.Variable(tf.ones(shape=(in_dim, out_dim)), tf.float32, name=\"W\")\n",
    "b = tf.Variable(tf.zeros(shape=(out_dim)), name=\"b\")\n",
    "\n",
    "@tf.function\n",
    "def linear_model(x):\n",
    "    return tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [[1., 0.]]\n",
    "x2 = [[1., 0.], [0., 1.]]\n",
    "x3 = [[1., 0.], [0., 1.], [1, 2]]\n",
    "\n",
    "print(linear_model(x1))\n",
    "print(linear_model(x2))\n",
    "print(linear_model(x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.assign([-1.,1])\n",
    "print(linear_model(x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic differentiation\n",
    "\n",
    "One of the main benefits of TensorFlow is its ability to perform gradient based optimization automatically. This is possible because the program is defined as a graph, so that it can trace the computation backwards and compute derivatives using the chain rule. These optimizers can be used to minimize a any tensor in the graph with respect to the the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "  loss = w * w\n",
    "\n",
    "grad = tape.gradient(loss, w)\n",
    "print(grad)  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a linear model\n",
    "\n",
    "We use the following operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.constant([[1.], [0.], [1], [10]])\n",
    "print(y)\n",
    "print(tf.squeeze(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in our revised definition of an affine linear model with a scalar output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 2\n",
    "\n",
    "W = tf.Variable(tf.ones(shape=(in_dim, 1), dtype=tf.float64), name=\"W\", dtype=tf.float64)\n",
    "b = tf.Variable(tf.zeros(shape=(1), dtype=tf.float64), name=\"b\", dtype=tf.float64)\n",
    "\n",
    "@tf.function\n",
    "def linear_model(x):\n",
    "    return tf.squeeze(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the mean-squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss(y, y_prime):\n",
    "    return tf.reduce_mean(tf.square(y-y_prime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define an optimizer, here the popular Adam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1., 0.], [0., 1.], [1, 2], [5, 10]])\n",
    "y = np.matmul(x, np.array([-1, 2])) - 1.\n",
    "for input, target in zip(x,y):\n",
    "    print(input, \"->\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear_model(x))\n",
    "print(loss(y,y))\n",
    "print(loss(y,linear_model(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comeas the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction  = linear_model(inputs)\n",
    "        loss_value = loss(prediction, targets)\n",
    "        grads = tape.gradient(loss_value, [W, b])\n",
    "    if (not ((i+1) % 10)):\n",
    "        print(i+1, \"{:.5f}\".format(loss_value))\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "\n",
    "for i in range(100):\n",
    "    train_step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "We want the whole training step to be executed on the GPU/TPU. Thus, we cannot simply `print` values.  Instead, we use concept of metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize variables \n",
    "W.assign(tf.ones(shape=(in_dim, 1), dtype=tf.float64))\n",
    "b.assign(tf.zeros(shape=(1), dtype=tf.float64))\n",
    "\n",
    "# Create the metric\n",
    "loss_metric = tf.metrics.Mean(name='train_loss')\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction  = linear_model(inputs)\n",
    "        loss_value = loss(prediction, targets)\n",
    "        grads = tape.gradient(loss_value, [W, b])\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "    loss_metric.update_state(loss_value)\n",
    "\n",
    "for i in range(0,100):\n",
    "    loss_metric.reset_states()\n",
    "    train_step(x, y)\n",
    "    if (not ((i+1) % 10)):\n",
    "        print(i+1, \"{:.5f}\".format(loss_metric.result()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
