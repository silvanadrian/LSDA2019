{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to build a k-d tree for the training set X_train to speed up the nearest neighbour computations for a nearest neighbor classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import copy\n",
    "import numpy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neighbours():\n",
    "    \"\"\" Class that can be used to keep track of the \n",
    "    k nearest neighbours computed. It also conducts\n",
    "    the \"brute-force\" phase that takes place in the\n",
    "    leaves of a k-d tree (see function 'add').\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        \n",
    "        self.k = k \n",
    "        \n",
    "        self._neighbors = [(None, None, float(\"inf\")) for i in range(self.k)]\n",
    "        \n",
    "    def get_dists_indices(self):\n",
    "        \n",
    "        indices = [neigh[1] for neigh in self._neighbors]\n",
    "        dists = [neigh[2] for neigh in self._neighbors]\n",
    "        \n",
    "        return numpy.array(dists), numpy.array(indices)\n",
    "    \n",
    "    def add(self, points, indices, query):\n",
    "        \n",
    "        for i in range(len(points)):\n",
    "            \n",
    "            p = points[i]\n",
    "            idx = indices[i]\n",
    "            dist = self._distance(p, query)\n",
    "            \n",
    "            self._neighbors.append([p,idx,dist])\n",
    "            self._neighbors = sorted(self._neighbors, key=lambda n: n[2])\n",
    "            self._neighbors = self._neighbors[:self.k]\n",
    "\n",
    "    def get_max_dist(self):\n",
    "        \n",
    "        return self._neighbors[-1][2]\n",
    "        \n",
    "    def _distance(self, x, y):\n",
    "        \n",
    "        dist = ((x-y)**2).sum()\n",
    "        return math.sqrt(dist)\n",
    "    \n",
    "class Node():\n",
    "    \"\"\" Class that represents a single node of\n",
    "    a k-d tree. If both 'left' and 'right' are \n",
    "    None, then the node is a leaf. The local \n",
    "    variables 'points' and 'indices' are used\n",
    "    to store the points/indices assigned to a \n",
    "    leaf.\n",
    "    \n",
    "    Otherwise, it is an internal node that \n",
    "    stores the median (splitting hyperplane)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 left, \n",
    "                 right, \n",
    "                 median=None, \n",
    "                 points=None, \n",
    "                 indices=None):\n",
    "\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.median = median\n",
    "        self.points = points\n",
    "        self.indices = indices\n",
    "        \n",
    "class KDTree():\n",
    "    \n",
    "    def __init__(self, leaf_size=30):\n",
    "        \"\"\" Instantiates a k-d tree.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        leaf_size : int, default 30\n",
    "            The leaf size, i.e., the maximal \n",
    "            number of points stored in a leaf \n",
    "            of the k-d tree.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.leaf_size = leaf_size\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n, d)\n",
    "            A Numpy array containing n data \n",
    "            points each having d features                \n",
    "        \"\"\"\n",
    "        \n",
    "        # remember dimension for which the tree was built\n",
    "        self._dim = len(X[0])\n",
    "        \n",
    "        # generate a list of the \"original\" indices that\n",
    "        # are processed in a similar way as the points; \n",
    "        # this is needed in order to obtain the indices\n",
    "        # of the neighbours compuated for a query.\n",
    "        original_indices = numpy.array(range(len(X)))\n",
    "        \n",
    "        # build tree recursively\n",
    "        self._root = self._build_tree(copy.deepcopy(X),\n",
    "                                      original_indices, \n",
    "                                      depth=0)     \n",
    "        \n",
    "    def query(self, X, k=1, max_leaves=None, alpha=1.0):\n",
    "        \"\"\" Computes the k nearest neighbors for each \n",
    "        point in X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n, d)\n",
    "            A Numpy array containing n data \n",
    "            points each having d features\n",
    "        k : int, default 1\n",
    "            The number of nearest neighbours to \n",
    "            be computed\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        dists, indices : arrays of shape (n, k)\n",
    "            Two arrays containing, for each query point,\n",
    "            the distances and the associated indices of\n",
    "            its k nearest neighbors w.r.t. the points\n",
    "            used for building the tree.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        \n",
    "        if self._root is None:  \n",
    "            raise Exception(\"Tree not fitted yet!\")\n",
    "            \n",
    "        if len(X[0]) != self._dim:\n",
    "            raise Exception(\"Tree was fitted for points of dimension: {}\".format(self._dim))\n",
    "        \n",
    "        # initialize two empty arrays that will be used to \n",
    "        # store the distances and the associated indices\n",
    "        dists = numpy.empty((len(X), k), dtype=numpy.float64)\n",
    "        indices = numpy.empty((len(X), k), dtype=numpy.int32)\n",
    "        \n",
    "        \n",
    "        # iterate over all query points\n",
    "        for i in range(len(X)):\n",
    "            \n",
    "            # set max-leaves\n",
    "            self.max_leaves=max_leaves\n",
    "            # initialize the neighbours object, which\n",
    "            # will keep track of the nearest neighbours\n",
    "            neighbours = Neighbours(k)\n",
    "            \n",
    "            # start recursive search\n",
    "            self._recursive_search(self._root, \n",
    "                                   X[i], \n",
    "                                   k, \n",
    "                                   depth=0, \n",
    "                                   neighbours=neighbours)\n",
    "            \n",
    "            # get the final distances and indices for \n",
    "            # the current query and store them at \n",
    "            # position i in the arrays dists and indices \n",
    "            dists_query, indices_query = neighbours.get_dists_indices()\n",
    "            dists[i,:] = dists_query\n",
    "            indices[i,:] = indices_query\n",
    "                \n",
    "        return dists, indices\n",
    "    \n",
    "    def _build_tree(self, pts, indices, depth):\n",
    "        \"\"\" Builds a k-d tree for the points given in pts. Since\n",
    "        we are also interested in the indidces afterwards, we also\n",
    "        keep track of the (original) indices.\n",
    "        \n",
    "        This code is similar to the pseudocode given on \n",
    "        slides 27-29 of L3_LSDA.pdf\n",
    "        \"\"\"\n",
    "        \n",
    "        # if only self.leaf_size points are left, stop\n",
    "        # the recursion and generate a leaf node\n",
    "        if len(pts) <= self.leaf_size: \n",
    "            \n",
    "            return Node(left=None, \n",
    "                        right=None, \n",
    "                        points=pts, \n",
    "                        indices=indices)\n",
    "        \n",
    "        # select axis\n",
    "        axis = depth % self._dim\n",
    "        \n",
    "        # sort the points w.r.t. dimension 'axis';\n",
    "        # also sort the indices accordingly\n",
    "        partition = pts[:,axis].argsort()\n",
    "        pts = pts[partition]\n",
    "        indices = indices[partition]\n",
    "        \n",
    "        # compute splitting index and median value\n",
    "        split_idx = math.floor(len(pts) / 2)\n",
    "        if len(pts) % 2 == 1:\n",
    "            median = pts[split_idx, axis]\n",
    "        else:\n",
    "            median = 0.5 * (pts[split_idx, axis] + pts[split_idx+1, axis])\n",
    "        \n",
    "        # build trees for children recursively ...\n",
    "        lefttree = self._build_tree(pts[:split_idx,:], indices[:split_idx], depth+1)\n",
    "        righttree = self._build_tree(pts[split_idx:,:], indices[split_idx:], depth+1)\n",
    "        \n",
    "        # return node storing all the relevant information\n",
    "        return Node(left=lefttree, right=righttree, median=median)\n",
    "\n",
    "    def _recursive_search(self, node, query, k, depth, neighbours):\n",
    "\n",
    "        if self.max_leaves == 0 and self.max_leaves != None:\n",
    "            return\n",
    "        \n",
    "        if (node.left == None and node.right==None):\n",
    "            neighbours.add(node.points, node.indices, query)\n",
    "            if self.max_leaves != None:\n",
    "                self.max_leaves -= 1\n",
    "            return\n",
    "        # axis to be checked (same order as during construction)\n",
    "        axis = depth % self._dim\n",
    "\n",
    "        # select next subtree candidate\n",
    "        if query[axis] < node.median:\n",
    "            first = node.left\n",
    "            second = node.right\n",
    "        else:\n",
    "            first = node.right\n",
    "            second = node.left\n",
    "\n",
    "        # check first subtree\n",
    "        self._recursive_search(first, query, k, depth+1, neighbours)\n",
    "\n",
    "        # while going up again (to the root): check if we \n",
    "        # still have to search in the second subtree! \n",
    "        if abs(node.median - query[axis]) < neighbours.get_max_dist()/self.alpha:\n",
    "            self._recursive_search(second, query, k, depth+1, neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class NearestNeighborClassifier(object):\n",
    "    \n",
    "    def __init__(self, n_neighbors=3, leaf_size=20, max_leaves=None, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.leaf_size = leaf_size\n",
    "        self.tree = KDTree(leaf_size=leaf_size)\n",
    "        self.max_leaves = max_leaves\n",
    "        self.alpha=alpha\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # fit with training data\n",
    "        self.tree.fit(X)\n",
    "        self.train = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        start = time.process_time()\n",
    "        dists, indices = self.tree.query(X,k=1,max_leaves=self.max_leaves,alpha=self.alpha)\n",
    "        elapsed = time.process_time() - start\n",
    "        print(\"Time needed in seconds:\", elapsed)\n",
    "        preds = []\n",
    "        for index in range(len(X)):\n",
    "            preds.append(np.argmax(np.bincount(self.train[indices[index]])))\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 580430\n",
      "Number of test instances: 582\n",
      "Number of features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get covtype data set; only make use of the first 10 features\n",
    "covtype = fetch_covtype()\n",
    "X, y = covtype.data, covtype.target\n",
    "X = X[:,:10]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=0)\n",
    "print(\"Number of training instances: {}\".format(X_train.shape[0]))\n",
    "print(\"Number of test instances: {}\".format(X_test.shape[0]))\n",
    "print(\"Number of features: {}\".format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate nearest neighbor classifier and fit/train model\n",
    "model = NearestNeighborClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed in seconds: 21.845542\n",
      "Final test accuracy: 0.9690721649484536\n"
     ]
    }
   ],
   "source": [
    "# Subtask 1.\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Final test accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed in seconds: 0.9807890000000015\n",
      "Final test accuracy: 0.9415807560137457\n"
     ]
    }
   ],
   "source": [
    "# Subtask 2.\n",
    "model = NearestNeighborClassifier(n_neighbors=3,max_leaves=10)\n",
    "model.fit(X_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Final test accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed in seconds: 7.842159000000002\n",
      "Final test accuracy: 0.9656357388316151\n"
     ]
    }
   ],
   "source": [
    "# Subtask 3.\n",
    "model = NearestNeighborClassifier(n_neighbors=3,alpha=2.0)\n",
    "model.fit(X_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Final test accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
