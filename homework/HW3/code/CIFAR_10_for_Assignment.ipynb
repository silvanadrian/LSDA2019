{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QWCLT5Nw5-Y"
   },
   "source": [
    "## CIFAR Example\n",
    "\n",
    "The basic architecture is taken from:\n",
    "\n",
    "https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/\n",
    "\n",
    "The notebook is supposed to run with TensorFlow 2.0.0-alpha0 and GPU support. In the following cell, it is assumed that you use Colaboratory and TensorFlow 2.0.0-alpha0 has to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "LlBl1MxZjhiF",
    "outputId": "08cb97e9-0de9-4501-9fec-8236263cab6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "\u001b[31m  Could not find a version that satisfies the requirement tensorflow-gpu==2.0.0-alpha0 (from versions: 0.12.0rc1, 0.12.0, 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0)\u001b[0m\n",
      "\u001b[31mNo matching distribution found for tensorflow-gpu==2.0.0-alpha0\u001b[0m\n",
      "TensorFlow version: 2.0.0-alpha0\n",
      "GPU available False\n",
      "Numpy version: 1.15.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available\", tf.test.is_gpu_available())\n",
    "\n",
    "import numpy as np\n",
    "print(\"Numpy version:\", np.version.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57MCsg_m81op"
   },
   "source": [
    "Donwload and normailze data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "oBeDQ4aQumzu",
    "outputId": "c4f21b39-2589-425f-e8cc-34d2bad9dbce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 79s 0us/step\n",
      "Mean of the three channels on the training data: [1.90680804e-17 9.16847154e-17 1.50768287e-17]\n",
      "Standard deviation of the three channels on the training data: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "mean = np.mean(x_train,axis=(0,1,2))\n",
    "std = np.std(x_train,axis=(0,1,2))\n",
    "x_train = (x_train-mean)/std\n",
    "x_test = (x_test-mean)/std\n",
    "\n",
    "print(\"Mean of the three channels on the training data:\", x_train.mean(axis=(0,1,2)))\n",
    "print(\"Standard deviation of the three channels on the training data:\", x_train.std(axis=(0,1,2)))\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ugWusk88-mj"
   },
   "source": [
    "Build model, train, and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3469
    },
    "colab_type": "code",
    "id": "1b0M83rMjiEA",
    "outputId": "4f58c32f-96b7-40d5-c3f1-7ec46f744513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_4 (Ba (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_5 (Ba (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/125\n",
      "687/781 [=========================>....] - ETA: 51s - loss: 1.4828 - accuracy: 0.4901"
     ]
    }
   ],
   "source": [
    "iiv = 0.01  # Standard deviation and offset for initializing bias parameters in hidden layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation=\"elu\", padding='same', \n",
    "  input_shape=x_train.shape[1:],\n",
    "  bias_initializer=tf.initializers.TruncatedNormal(mean=iiv, stddev=iiv)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation=\"elu\", padding='same', \n",
    "  bias_initializer=tf.initializers.TruncatedNormal(mean=iiv, stddev=iiv)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation=\"elu\", padding='same', \n",
    "  bias_initializer=tf.initializers.TruncatedNormal(mean=iiv, stddev=iiv)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation=\"elu\", padding='same', \n",
    "  bias_initializer=tf.initializers.TruncatedNormal(mean=iiv, stddev=iiv)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation=\"elu\", padding='same', \n",
    "  bias_initializer=tf.initializers.TruncatedNormal(mean=iiv, stddev=iiv)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation=\"elu\", padding='same', \n",
    "  bias_initializer=tf.initializers.TruncatedNormal(mean=iiv, stddev=iiv)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    " \n",
    "# Data augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    " \n",
    "# Training\n",
    "batch_size = 64\n",
    "   \n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)  # The decay parameter controls a schedule that reduces the learning rate parameter over time\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size, epochs=125,\n",
    "                    verbose=1, validation_data=(x_test,y_test))\n",
    "\n",
    "# Testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onYwD6nbjyTj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR 10 for Assignment",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
